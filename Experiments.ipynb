{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "T = 250 # how long to simulate the trajectory\n",
    "state_dim = 2 # Dimension of the state-space\n",
    "input_dim = 1 # Dimension of inputs\n",
    "obs_dim = state_dim # for now\n",
    "NUM_TRAJ_TRAIN = 100 # number of trajectories to simulate for training data\n",
    "NUM_TRAJ_TEST = 20\n",
    "num_trajs = NUM_TRAJ_TRAIN + NUM_TRAJ_TEST\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 1/360*2*np.pi # one degree\n",
    "\n",
    "A = np.array([[np.cos(theta), -np.sin(theta)], # state transition matrix\n",
    "              [np.sin(theta),  np.cos(theta)]]) # moving around a circle at 1 deg per timestep\n",
    "B = np.array([[0.5], [0.7]]) # input transformation\n",
    "# B = np.zeros(shape=(state_dim, input_dim)) # ignore inputs for now\n",
    "C = np.eye(obs_dim, state_dim) # Using identity map for now\n",
    "Q = 0.001*np.eye(state_dim) # Covariance matrix of process noise\n",
    "R = 0.01*np.eye(obs_dim) # Covariance matrix of sensor noise\n",
    "x0 = np.array([1.0, 0.0], dtype=np.float64) # starting state\n",
    "u_seq = 0.05 * (rng.random(size=(num_trajs, T, input_dim))*2 - 1)\n",
    "traj = np.zeros(shape=(num_trajs, T, state_dim))\n",
    "meas = np.zeros(shape=(num_trajs, T, obs_dim))\n",
    "\n",
    "for traj_index in range(num_trajs):\n",
    "    x = x0\n",
    "    for i in range(T):\n",
    "        u_t = u_seq[traj_index, i]\n",
    "        w_t = rng.multivariate_normal(mean=np.zeros(state_dim), cov=Q) # process noise\n",
    "        x = A @ x + w_t + B @ u_t # inputs\n",
    "        v_t = rng.multivariate_normal(mean=np.zeros(obs_dim), cov=R) # sensor noise\n",
    "        y = C @ x + v_t\n",
    "        traj[traj_index, i] = x\n",
    "        meas[traj_index, i] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_visualize = 1\n",
    "\n",
    "# plot trajectory and noisy measurements\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "linetraj, = ax.plot(traj[index_to_visualize, :,0], traj[index_to_visualize, :,1], label='Trajectory')\n",
    "linemeas, = ax.plot(meas[index_to_visualize, :,0], meas[index_to_visualize, :,1], label='Measured')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's see if a transformer can learn the dynamics and filter the position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import *\n",
    "from transformer_attention import AttentionQKV\n",
    "from transformer_attention import MultiHeadProjection\n",
    "from transformer import PositionEmbedding\n",
    "\n",
    "embed_dim = 36 # use 36-dimensional embedding for now\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "indices_train = np.arange(NUM_TRAJ_TRAIN)\n",
    "np.random.shuffle(indices_train)\n",
    "\n",
    "# The input to the model will be a concatenation of the current measured state and the \"u\" input at this timestep\n",
    "target_sequences_train = torch.from_numpy(meas)[indices_train,:,:]\n",
    "input_sequences_train = torch.from_numpy(u_seq)[indices_train,:,:]\n",
    "transformer_input_train = torch.cat((target_sequences_train, input_sequences_train), dim=2)\n",
    "\n",
    "# Test Data\n",
    "indices_test = np.arange(NUM_TRAJ_TRAIN, NUM_TRAJ_TRAIN+NUM_TRAJ_TEST)\n",
    "np.random.shuffle(indices_test)\n",
    "\n",
    "traj_test = traj[indices_test,:,:]\n",
    "meas_test = meas[indices_test,:,:]\n",
    "target_sequences_test = torch.from_numpy(meas)[indices_test,:,:]\n",
    "input_sequences_test = torch.from_numpy(u_seq)[indices_test,:,:]\n",
    "transformer_input_test = torch.cat((target_sequences_test, input_sequences_test), dim=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-style: Transformer Decoder only for Autoregressive generation\n",
    "\n",
    "Compare to:\n",
    "* Just the last timestep (ZOH) \n",
    "* Run A, B system on last timesteps (no noise) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "gpt_model = TransformerDecoder(seq_input_size=(obs_dim+input_dim), embed_size=embed_dim, output_size=state_dim,\n",
    "                 n_layers=3, n_heads=6, d_filter=256, dropout=None)\n",
    "optimizer = torch.optim.Adam(gpt_model.parameters())\n",
    "\n",
    "losses = []\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for batchNum in range(NUM_TRAJ_TRAIN // batch_size):\n",
    "        \n",
    "        transformer_input_batch = transformer_input_train[batchNum*batch_size:(batchNum+1)*batch_size, :, :]\n",
    "        target_sequence_batch = target_sequences_train[batchNum*batch_size:(batchNum+1)*batch_size, :, :]  \n",
    "        \n",
    "#         print(transformer_input_batch.shape)\n",
    "#         print(target_sequence_batch.shape)\n",
    "        decoder_output = gpt_model(transformer_input_batch, decoder_mask=None, mask_future=True, shift_target_sequence_right=True)\n",
    "\n",
    "        loss = loss_func(decoder_output, target_sequence_batch)# [:, 1:, :])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        losses.append(curr_loss)\n",
    "        \n",
    "    print('Epoch', i, \": Loss\", curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses[30:])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_transformer_sim = gpt_model(transformer_input_test, decoder_mask=None, mask_future=True, shift_target_sequence_right=False)\n",
    "\n",
    "# Index that we want to visualize from the test indices\n",
    "ind_to_vis = 4\n",
    "\n",
    "filtered = gpt_transformer_sim.detach().numpy()\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "linetraj, = ax.plot(traj_test[ind_to_vis, :,0], traj_test[ind_to_vis, :,1], label='Trajectory')\n",
    "linemeas, = ax.plot(meas_test[ind_to_vis, :,0], meas_test[ind_to_vis, :,1], label='Measured')\n",
    "linegpt, = ax.plot(filtered[ind_to_vis, :, 0], filtered[ind_to_vis, :, 1], label='Filtered by GPT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Error between traj and meas', np.linalg.norm(traj_test - meas_test) / NUM_TRAJ_TEST)\n",
    "print('Error between filtered and traj', np.linalg.norm(filtered - traj_test) / NUM_TRAJ_TEST)\n",
    "print('Error between filtered and meas', np.linalg.norm(filtered - meas_test) / NUM_TRAJ_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT-style: Transformer Encoder only, fill in the blanks for the trajectory \n",
    "\n",
    "Compare to: \n",
    "* Average between different timesteps for the missing ones (PWL linear interpolation)\n",
    "* Just the last step (ZOH interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 40\n",
    "p = 0.15 # probability of zeroing out a token\n",
    "\n",
    "bert_model = TransformerEncoder(seq_input_size=(obs_dim+input_dim), # size of the input tokens (obs_dim + input_dim)\n",
    "                embed_size=embed_dim, output_size=state_dim, \n",
    "                n_layers=3, n_heads=6, d_filter=256, \n",
    "                dropout=None)\n",
    "optimizer = torch.optim.Adam(bert_model.parameters())\n",
    "\n",
    "#Randomly zero-out 20% of the tokens in target_sequences_train\n",
    "mask = torch.bernoulli( (1-p) * torch.ones(size=(NUM_TRAJ_TRAIN, T) ) )\n",
    "mask = mask.repeat(obs_dim+input_dim, 1, 1).permute(1, 2, 0)\n",
    "# print(\"mask is\", mask)\n",
    "\n",
    "transformer_input_train_masked = transformer_input_train * mask\n",
    "\n",
    "loss_func = torch.nn.MSELoss(reduction='sum')\n",
    "losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for batchNum in range(NUM_TRAJ_TRAIN // batch_size):\n",
    "        \n",
    "        transformer_input_batch = transformer_input_train_masked[batchNum*batch_size:(batchNum+1)*batch_size, :, :]\n",
    "        # transformer_input_batch has shape [batch_size, seq_len, (obs_dim+input_dim)] \n",
    "        \n",
    "        target_sequence_batch = target_sequences_train[batchNum*batch_size:(batchNum+1)*batch_size, :, :]\n",
    "       \n",
    "         # What percent of them are zeroed out?\n",
    "#         zeroed = 0\n",
    "#         for batch in transformer_input_batch:\n",
    "#             for seq_elt in batch:\n",
    "#                 if all(seq_elt == 0.0): zeroed += 1\n",
    "#         print(\"percent zeroed\", zeroed / (batch_size * T) )\n",
    "        \n",
    "        encoder_output = bert_model(transformer_input_batch, encoder_mask=None)\n",
    "\n",
    "        loss = loss_func(encoder_output, target_sequence_batch)# [:, 1:, :])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        curr_loss = loss.item()\n",
    "        losses.append(curr_loss)\n",
    "        \n",
    "    print('Epoch', i, \": Loss\", curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses[30:])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_transformer_sim = bert_model(transformer_input_test, encoder_mask=None)\n",
    "\n",
    "# Index that we want to visualize from the test indices\n",
    "ind_to_vis = 12\n",
    "\n",
    "filtered = bert_transformer_sim.detach().numpy()\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "linetraj, = ax.plot(traj_test[ind_to_vis, :,0], traj_test[ind_to_vis, :,1], label='Trajectory')\n",
    "linemeas, = ax.plot(meas_test[ind_to_vis, :,0], meas_test[ind_to_vis, :,1], label='Measured')\n",
    "linegpt, = ax.plot(filtered[ind_to_vis, :, 0], filtered[ind_to_vis, :, 1], label='Filtered by BERT')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Error between traj and meas', np.linalg.norm(traj_test - meas_test) / NUM_TRAJ_TEST)\n",
    "print('Error between filtered and traj', np.linalg.norm(filtered - traj_test) / NUM_TRAJ_TEST)\n",
    "print('Error between filtered and meas', np.linalg.norm(filtered - meas_test) / NUM_TRAJ_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
